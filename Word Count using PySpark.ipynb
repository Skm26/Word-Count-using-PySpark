{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0485ba98-7d96-4c45-8a38-886462baee10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder\\\n",
    ".master(\"local\")\\\n",
    ".appName(\"Word Count\")\\\n",
    ".getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf729e64-fbf0-4b6f-92ca-e73f47bd65a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd=sc.textFile(\"dbfs:/FileStore/shared_uploads/sanjaykarthikm26@gmail.com/wordcount.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58ba2d2d-9235-4d53-a90b-01642691cdfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: ['Apache Spark is a unified analytics engine for large-scale data processing.',\n 'It provides high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs.',\n 'It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.']"
     ]
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a3269c9-9bb3-47f5-a5da-f5701b90809b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spli the words\n",
    "splitrdd=rdd.flatMap(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82567e9-8c6d-4cc1-b86a-30f079cb5e1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in splitRDD: 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in splitRDD:\", splitrdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03cb588e-e689-4167-a29e-f85b2520a0d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\nCollecting tqdm\n  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk) (8.0.4)\nCollecting regex>=2021.8.3\n  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk) (1.1.1)\nInstalling collected packages: tqdm, regex, nltk\nSuccessfully installed nltk-3.8.1 regex-2023.12.25 tqdm-4.66.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9224ab5-d533-4bb5-91ad-c667a15bf17f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a473cf20-c546-4478-858e-28cd9bb8389e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Removing the stop words\n",
    "newrdd=splitrdd.filter(lambda x: x.lower() not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9645d77f-afaa-4e69-84e6-01faaddd0f0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: 42"
     ]
    }
   ],
   "source": [
    "newrdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f13dcda-f3ad-44ab-88e9-ff1a525ea7c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Map each word with value 1\n",
    "mrdd=newrdd.map(lambda w:(w,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48d123e-08c5-424c-b1c3-42e07f4d4c2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: [('Apache', 1),\n ('Spark', 1),\n ('unified', 1),\n ('analytics', 1),\n ('engine', 1),\n ('large-scale', 1),\n ('data', 1),\n ('processing.', 1),\n ('provides', 1),\n ('high-level', 1),\n ('APIs', 1),\n ('Java,', 1),\n ('Scala,', 1),\n ('Python,', 1),\n ('R,', 1),\n ('optimized', 1),\n ('engine', 1),\n ('supports', 1),\n ('general', 1),\n ('execution', 1),\n ('graphs.', 1),\n ('also', 1),\n ('supports', 1),\n ('rich', 1),\n ('set', 1),\n ('higher-level', 1),\n ('tools', 1),\n ('including', 1),\n ('Spark', 1),\n ('SQL', 1),\n ('SQL', 1),\n ('structured', 1),\n ('data', 1),\n ('processing,', 1),\n ('MLlib', 1),\n ('machine', 1),\n ('learning,', 1),\n ('GraphX', 1),\n ('graph', 1),\n ('processing,', 1),\n ('Spark', 1),\n ('Streaming.', 1)]"
     ]
    }
   ],
   "source": [
    "mrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "166ca1c9-75d9-4aa4-9172-1cf25d535f7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grdd=mrdd.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31fa46d9-020a-4cf0-a42e-7f511a64b2a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: [('Apache', 1),\n ('Spark', 3),\n ('unified', 1),\n ('analytics', 1),\n ('engine', 2),\n ('provides', 1),\n ('high-level', 1),\n ('APIs', 1),\n ('Java,', 1),\n ('Scala,', 1),\n ('optimized', 1),\n ('supports', 2),\n ('execution', 1),\n ('set', 1),\n ('tools', 1),\n ('SQL', 2),\n ('processing,', 2),\n ('MLlib', 1),\n ('machine', 1),\n ('learning,', 1),\n ('GraphX', 1),\n ('graph', 1),\n ('Streaming.', 1),\n ('large-scale', 1),\n ('data', 2),\n ('processing.', 1),\n ('Python,', 1),\n ('R,', 1),\n ('general', 1),\n ('graphs.', 1),\n ('also', 1),\n ('rich', 1),\n ('higher-level', 1),\n ('including', 1),\n ('structured', 1)]"
     ]
    }
   ],
   "source": [
    "grdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12285539-fc93-4023-83b6-d20bd29a3811",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "swaprdd=grdd.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9edaa76a-d1d0-4676-a905-8d20f3346058",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "swapsort=swaprdd.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3fdf20a-7379-4002-bb1a-4f251868b8f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: [(3, 'Spark'), (2, 'engine')]"
     ]
    }
   ],
   "source": [
    "swapsort.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567fee9d-5af1-4c81-a64c-6ef84d638dd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark,3\nengine,2\nsupports,2\nSQL,2\nprocessing,,2\ndata,2\nApache,1\nunified,1\nanalytics,1\nprovides,1\n"
     ]
    }
   ],
   "source": [
    "for word in swapsort.take(10):\n",
    "    print(\"{},{}\". format(word[1], word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "320d2bd9-1bb9-4742-bed3-fdad12d6c4d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Using a Single Rdd\n",
    "rdd1=sc.textFile(\"dbfs:/FileStore/shared_uploads/sanjaykarthikm26@gmail.com/wordcount.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d3b178-f792-40fc-94a9-e2ca23215060",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd2=rdd1.flatMap(lambda x:x.split()) \\\n",
    "    .filter(lambda x: x.lower() not in stop_words) \\\n",
    "        .map(lambda w:(w,1)) \\\n",
    "            .reduceByKey(lambda x,y:x+y) \\\n",
    "                .map(lambda x:(x[1],x[0])) \\\n",
    "                    .sortByKey(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50fdd1c0-65ba-4a05-97a5-ca99c8caaf39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark,3\nengine,2\nsupports,2\nSQL,2\nprocessing,,2\ndata,2\nApache,1\nunified,1\nanalytics,1\nprovides,1\n"
     ]
    }
   ],
   "source": [
    "for word in rdd2.take(10):\n",
    "    print(\"{},{}\". format(word[1], word[0]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3913256529469241,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Word Count using PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
